#!/usr/bin/env python3
"""
ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¾Œç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®ä¸€å®šæœŸé–“ã€ã‚·ã‚¹ãƒ†ãƒ ã®å¥å…¨æ€§ã‚’ç›£è¦–ã—ã€å•é¡ŒãŒã‚ã‚Œã°ã‚¢ãƒ©ãƒ¼ãƒˆã‚’é€ä¿¡
"""

import argparse
import json
import time
import logging
import sys
import subprocess
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import threading
import queue

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PostDeploymentMonitor:
    """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¾Œç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, service_name: str, region: str = "asia-northeast1"):
        self.service_name = service_name
        self.region = region
        self.monitoring_active = True
        self.alert_queue = queue.Queue()
        
        # ç›£è¦–é–¾å€¤
        self.thresholds = {
            "error_rate": 0.05,      # 5%
            "response_time_p95": 1200,  # 1.2ç§’ï¼ˆãƒŸãƒªç§’ï¼‰
            "cpu_utilization": 0.8,   # 80%
            "memory_utilization": 0.8, # 80%
            "request_rate_drop": 0.5   # 50%æ¸›å°‘
        }
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.baseline_metrics = {}
    
    def run_command(self, command: List[str]) -> Tuple[bool, str, str]:
        """ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ"""
        try:
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                timeout=60,
                check=True
            )
            return True, result.stdout, result.stderr
        except subprocess.CalledProcessError as e:
            return False, e.stdout, e.stderr
        except subprocess.TimeoutExpired:
            return False, "", "Command timed out"
    
    def get_service_url(self) -> Optional[str]:
        """ã‚µãƒ¼ãƒ“ã‚¹URLã‚’å–å¾—"""
        command = [
            "gcloud", "run", "services", "describe", self.service_name,
            "--region", self.region,
            "--format", "value(status.url)"
        ]
        
        success, stdout, stderr = self.run_command(command)
        
        if success and stdout.strip():
            return stdout.strip()
        return None
    
    def health_check(self, url: str) -> Dict:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        health_url = f"{url}/health"
        
        try:
            start_time = time.time()
            response = requests.get(health_url, timeout=10)
            response_time = (time.time() - start_time) * 1000  # ãƒŸãƒªç§’
            
            return {
                "status": "healthy" if response.status_code == 200 else "unhealthy",
                "status_code": response.status_code,
                "response_time": response_time,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "response_time": None,
                "timestamp": datetime.now().isoformat()
            }
    
    def get_error_rate(self, minutes: int = 5) -> float:
        """ã‚¨ãƒ©ãƒ¼ç‡ã‚’å–å¾—"""
        try:
            # Cloud Loggingã‹ã‚‰ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å–å¾—
            command = [
                "gcloud", "logging", "read",
                f'resource.type="cloud_run_revision" AND resource.labels.service_name="{self.service_name}" AND severity>=ERROR',
                "--limit", "1000",
                "--format", "json",
                f"--freshness", f"{minutes}m"
            ]
            
            success, stdout, stderr = self.run_command(command)
            
            if success and stdout.strip():
                error_logs = json.loads(stdout)
                error_count = len(error_logs)
            else:
                error_count = 0
            
            # å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’å–å¾—
            command = [
                "gcloud", "logging", "read",
                f'resource.type="cloud_run_revision" AND resource.labels.service_name="{self.service_name}"',
                "--limit", "1000",
                "--format", "json",
                f"--freshness", f"{minutes}m"
            ]
            
            success, stdout, stderr = self.run_command(command)
            
            if success and stdout.strip():
                all_logs = json.loads(stdout)
                total_count = len(all_logs)
            else:
                total_count = 0
            
            if total_count > 0:
                error_rate = error_count / total_count
            else:
                error_rate = 0.0
            
            logger.info(f"ã‚¨ãƒ©ãƒ¼ç‡: {error_rate:.3f} ({error_count}/{total_count})")
            return error_rate
            
        except Exception as e:
            logger.error(f"ã‚¨ãƒ©ãƒ¼ç‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def get_response_time_metrics(self, minutes: int = 5) -> Dict:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        try:
            # Cloud Monitoringã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’å–å¾—
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Cloud Monitoring APIã‚’ä½¿ç”¨
            
            # ç°¡æ˜“çš„ãªå®Ÿè£…ã¨ã—ã¦ã€ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’ä½¿ç”¨
            service_url = self.get_service_url()
            if not service_url:
                return {"p95": 0, "avg": 0, "count": 0}
            
            response_times = []
            for _ in range(10):  # 10å›æ¸¬å®š
                health_result = self.health_check(service_url)
                if health_result.get("response_time"):
                    response_times.append(health_result["response_time"])
                time.sleep(1)
            
            if response_times:
                response_times.sort()
                count = len(response_times)
                avg = sum(response_times) / count
                p95_index = int(count * 0.95)
                p95 = response_times[p95_index] if p95_index < count else response_times[-1]
                
                return {"p95": p95, "avg": avg, "count": count}
            else:
                return {"p95": 0, "avg": 0, "count": 0}
                
        except Exception as e:
            logger.error(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"p95": 0, "avg": 0, "count": 0}
    
    def get_resource_utilization(self) -> Dict:
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã‚’å–å¾—"""
        try:
            # Cloud Monitoringã‹ã‚‰ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã‚’å–å¾—
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Cloud Monitoring APIã‚’ä½¿ç”¨
            
            # ç°¡æ˜“çš„ãªå®Ÿè£…ã¨ã—ã¦ã€å›ºå®šå€¤ã‚’è¿”ã™
            return {
                "cpu_utilization": 0.3,  # 30%
                "memory_utilization": 0.4,  # 40%
                "instance_count": 5
            }
            
        except Exception as e:
            logger.error(f"ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "cpu_utilization": 0.0,
                "memory_utilization": 0.0,
                "instance_count": 0
            }
    
    def collect_metrics(self) -> Dict:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        logger.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ä¸­...")
        
        # å„ç¨®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¸¦è¡Œã—ã¦å–å¾—
        error_rate = self.get_error_rate()
        response_metrics = self.get_response_time_metrics()
        resource_metrics = self.get_resource_utilization()
        
        service_url = self.get_service_url()
        health_result = self.health_check(service_url) if service_url else {"status": "unknown"}
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "service_name": self.service_name,
            "health_status": health_result.get("status"),
            "error_rate": error_rate,
            "response_time_p95": response_metrics.get("p95", 0),
            "response_time_avg": response_metrics.get("avg", 0),
            "cpu_utilization": resource_metrics.get("cpu_utilization", 0),
            "memory_utilization": resource_metrics.get("memory_utilization", 0),
            "instance_count": resource_metrics.get("instance_count", 0)
        }
        
        return metrics
    
    def check_thresholds(self, metrics: Dict) -> List[Dict]:
        """é–¾å€¤ãƒã‚§ãƒƒã‚¯"""
        alerts = []
        
        # ã‚¨ãƒ©ãƒ¼ç‡ãƒã‚§ãƒƒã‚¯
        if metrics["error_rate"] > self.thresholds["error_rate"]:
            alerts.append({
                "type": "error_rate",
                "severity": "critical",
                "message": f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé–¾å€¤ã‚’è¶…é: {metrics['error_rate']:.3f} > {self.thresholds['error_rate']:.3f}",
                "value": metrics["error_rate"],
                "threshold": self.thresholds["error_rate"]
            })
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãƒã‚§ãƒƒã‚¯
        if metrics["response_time_p95"] > self.thresholds["response_time_p95"]:
            alerts.append({
                "type": "response_time",
                "severity": "warning",
                "message": f"P95ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒé–¾å€¤ã‚’è¶…é: {metrics['response_time_p95']:.1f}ms > {self.thresholds['response_time_p95']}ms",
                "value": metrics["response_time_p95"],
                "threshold": self.thresholds["response_time_p95"]
            })
        
        # CPUä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if metrics["cpu_utilization"] > self.thresholds["cpu_utilization"]:
            alerts.append({
                "type": "cpu_utilization",
                "severity": "warning",
                "message": f"CPUä½¿ç”¨ç‡ãŒé–¾å€¤ã‚’è¶…é: {metrics['cpu_utilization']:.1%} > {self.thresholds['cpu_utilization']:.1%}",
                "value": metrics["cpu_utilization"],
                "threshold": self.thresholds["cpu_utilization"]
            })
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if metrics["memory_utilization"] > self.thresholds["memory_utilization"]:
            alerts.append({
                "type": "memory_utilization",
                "severity": "warning",
                "message": f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé–¾å€¤ã‚’è¶…é: {metrics['memory_utilization']:.1%} > {self.thresholds['memory_utilization']:.1%}",
                "value": metrics["memory_utilization"],
                "threshold": self.thresholds["memory_utilization"]
            })
        
        # ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯
        if metrics["health_status"] != "healthy":
            alerts.append({
                "type": "health_check",
                "severity": "critical",
                "message": f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—: {metrics['health_status']}",
                "value": metrics["health_status"],
                "threshold": "healthy"
            })
        
        return alerts
    
    def send_alert(self, alert: Dict) -> bool:
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        try:
            # Slackã‚„ãƒ¡ãƒ¼ãƒ«ã€PagerDutyãªã©ã«ã‚¢ãƒ©ãƒ¼ãƒˆã‚’é€ä¿¡
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€é©åˆ‡ãªé€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
            
            alert_message = {
                "service": self.service_name,
                "alert": alert,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.warning(f"ğŸš¨ ALERT: {alert['message']}")
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²
            with open(f"alert_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", "w") as f:
                json.dump(alert_message, f, indent=2)
            
            return True
            
        except Exception as e:
            logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_monitoring_report(self, metrics_history: List[Dict]) -> Dict:
        """ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not metrics_history:
            return {"status": "no_data"}
        
        # çµ±è¨ˆè¨ˆç®—
        error_rates = [m["error_rate"] for m in metrics_history]
        response_times = [m["response_time_p95"] for m in metrics_history if m["response_time_p95"] > 0]
        
        report = {
            "monitoring_period": {
                "start": metrics_history[0]["timestamp"],
                "end": metrics_history[-1]["timestamp"],
                "duration_minutes": len(metrics_history)
            },
            "summary": {
                "total_samples": len(metrics_history),
                "avg_error_rate": sum(error_rates) / len(error_rates) if error_rates else 0,
                "max_error_rate": max(error_rates) if error_rates else 0,
                "avg_response_time_p95": sum(response_times) / len(response_times) if response_times else 0,
                "max_response_time_p95": max(response_times) if response_times else 0
            },
            "health_status": {
                "healthy_samples": sum(1 for m in metrics_history if m["health_status"] == "healthy"),
                "unhealthy_samples": sum(1 for m in metrics_history if m["health_status"] != "healthy"),
                "availability": sum(1 for m in metrics_history if m["health_status"] == "healthy") / len(metrics_history)
            },
            "threshold_violations": {
                "error_rate": sum(1 for m in metrics_history if m["error_rate"] > self.thresholds["error_rate"]),
                "response_time": sum(1 for m in metrics_history if m["response_time_p95"] > self.thresholds["response_time_p95"])
            }
        }
        
        # å…¨ä½“è©•ä¾¡
        if report["summary"]["max_error_rate"] > self.thresholds["error_rate"]:
            report["overall_status"] = "critical"
        elif report["threshold_violations"]["response_time"] > len(metrics_history) * 0.1:  # 10%ä»¥ä¸Šã®é•å
            report["overall_status"] = "warning"
        else:
            report["overall_status"] = "healthy"
        
        return report
    
    def monitor(self, duration_minutes: int, interval_seconds: int = 60) -> Dict:
        """ç›£è¦–å®Ÿè¡Œ"""
        logger.info(f"ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¾Œç›£è¦–é–‹å§‹: {duration_minutes}åˆ†é–“")
        
        metrics_history = []
        alert_count = 0
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        
        try:
            while time.time() < end_time and self.monitoring_active:
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
                metrics = self.collect_metrics()
                metrics_history.append(metrics)
                
                # é–¾å€¤ãƒã‚§ãƒƒã‚¯
                alerts = self.check_thresholds(metrics)
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
                for alert in alerts:
                    self.send_alert(alert)
                    alert_count += 1
                
                # é€²æ—è¡¨ç¤º
                elapsed_minutes = (time.time() - start_time) / 60
                logger.info(f"ç›£è¦–é€²æ—: {elapsed_minutes:.1f}/{duration_minutes}åˆ† (ã‚¢ãƒ©ãƒ¼ãƒˆ: {alert_count}ä»¶)")
                
                # æ¬¡ã®ç›£è¦–ã¾ã§å¾…æ©Ÿ
                time.sleep(interval_seconds)
            
            # ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_monitoring_report(metrics_history)
            report["alert_count"] = alert_count
            
            logger.info(f"ç›£è¦–å®Œäº†: å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={report['overall_status']}, ã‚¢ãƒ©ãƒ¼ãƒˆ={alert_count}ä»¶")
            
            return report
            
        except KeyboardInterrupt:
            logger.info("ç›£è¦–ä¸­æ–­")
            self.monitoring_active = False
            return self.generate_monitoring_report(metrics_history)
        except Exception as e:
            logger.error(f"ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "error": str(e)}
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring_active = False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¾Œç›£è¦–")
    parser.add_argument("--service", required=True, help="Cloud Runã‚µãƒ¼ãƒ“ã‚¹å")
    parser.add_argument("--region", default="asia-northeast1", help="ãƒªãƒ¼ã‚¸ãƒ§ãƒ³")
    parser.add_argument("--duration", type=int, default=15, help="ç›£è¦–æ™‚é–“ï¼ˆåˆ†ï¼‰")
    parser.add_argument("--interval", type=int, default=60, help="ç›£è¦–é–“éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--alert-threshold", type=float, default=0.05, help="ã‚¨ãƒ©ãƒ¼ç‡ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤")
    parser.add_argument("--output", help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    
    args = parser.parse_args()
    
    # ç›£è¦–é–‹å§‹
    monitor = PostDeploymentMonitor(args.service, args.region)
    
    # é–¾å€¤è¨­å®š
    if args.alert_threshold:
        monitor.thresholds["error_rate"] = args.alert_threshold
    
    try:
        # ç›£è¦–å®Ÿè¡Œ
        report = monitor.monitor(args.duration, args.interval)
        
        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        if args.output:
            with open(args.output, "w") as f:
                json.dump(report, f, indent=2)
            logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {args.output}")
        else:
            print(json.dumps(report, indent=2))
        
        # çµ‚äº†ã‚³ãƒ¼ãƒ‰æ±ºå®š
        if report.get("overall_status") == "critical":
            sys.exit(2)  # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«
        elif report.get("overall_status") == "warning":
            sys.exit(1)  # è­¦å‘Š
        else:
            sys.exit(0)  # æ­£å¸¸
            
    except KeyboardInterrupt:
        logger.info("ç›£è¦–ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()