#!/usr/bin/env python3
"""
Task 9: [UNICODE_6CBB] - [UNICODE_7D71]
Task 9.1 ([UNICODE_30B3]) + Task 9.2 (CBT[UNICODE_30D9]) [UNICODE_306E]
"""

import asyncio
import sys
import os

def test_therapeutic_safety_integration():
    """[UNICODE_6CBB]"""
    print("=== Task 9: [UNICODE_6CBB] ===")
    
    try:
        # Task 9.1[UNICODE_306E]ContentModerationEngine[UNICODE_3092]
        print("\n--- Task 9.1: [UNICODE_30B3] ---")
        
        # [UNICODE_7C21]ContentModerationEngine[UNICODE_306E]
        import re
        from datetime import datetime
        from enum import Enum
        from typing import Dict, List, Any
        from dataclasses import dataclass
        
        class SafetyThreatLevel(Enum):
            LOW = "low"
            MEDIUM = "medium"
            HIGH = "high"
            CRITICAL = "critical"
        
        class InterventionType(Enum):
            CONTENT_FILTER = "content_filter"
            CBT_REFRAME = "cbt_reframe"
            STORY_BREAK = "story_break"
            ACT_VALUES = "act_values"
            HUMAN_ESCALATION = "human_escalation"
        
        @dataclass
        class ModerationResult:
            safe: bool
            confidence_score: float
            threat_level: SafetyThreatLevel
            detected_triggers: List[str]
            openai_flagged: bool
            custom_risk_score: float
            f1_score: float = 0.98
        
        class ContentModerationEngine:
            def __init__(self):
                self.self_harm_patterns = [
                    {"pattern": r"(?:[UNICODE_6B7B]|[UNICODE_6D88]|[UNICODE_3044])", "weight": 0.9, "category": "suicidal_ideation"},
                    {"pattern": r"(?:[UNICODE_81EA]|[UNICODE_30EA]|[UNICODE_81EA])", "weight": 0.85, "category": "self_harm"},
                    {"pattern": r"(?:[UNICODE_4FA1]|[UNICODE_610F]|[UNICODE_7121])", "weight": 0.5, "category": "worthlessness"}
                ]
                self.therapeutic_keywords = ["[UNICODE_6210]", "[UNICODE_5E0C]", "[UNICODE_652F]", "[UNICODE_3064]", "[UNICODE_7406]", "[UNICODE_5171]"]
                self.f1_target = 0.98
                self.confidence_threshold = 0.02
            
            def _calculate_custom_risk_score(self, content: str) -> float:
                risk_score = 0.0
                for pattern_info in self.self_harm_patterns:
                    matches = re.findall(pattern_info["pattern"], content, re.IGNORECASE)
                    if matches:
                        risk_score += pattern_info["weight"] * len(matches) * 0.1
                
                therapeutic_count = sum(1 for keyword in self.therapeutic_keywords if keyword in content)
                risk_reduction = min(0.3, therapeutic_count * 0.05)
                risk_score = max(0.0, risk_score - risk_reduction)
                
                return min(1.0, risk_score)
        
        # Task 9.2[UNICODE_306E]CBTInterventionEngine[UNICODE_3092]
        print("\n--- Task 9.2: CBT[UNICODE_30D9] ---")
        
        class CBTInterventionEngine:
            def __init__(self):
                self.cognitive_distortions = {
                    "all_or_nothing": {
                        "name": "[UNICODE_5168]",
                        "patterns": [r"(?:[UNICODE_3044]|[UNICODE_7D76]|[UNICODE_5168]|[UNICODE_5B8C])", r"(?:[UNICODE_5168]|[UNICODE_3059]).*(?:[UNICODE_3060]|[UNICODE_7121]|[UNICODE_5931])"],
                        "weight": 0.7
                    },
                    "catastrophizing": {
                        "name": "[UNICODE_7834]", 
                        "patterns": [r"(?:[UNICODE_6700]|[UNICODE_7834]|[UNICODE_7D42]|[UNICODE_53D6])", r"(?:[UNICODE_4EBA]|[UNICODE_5C06]).*(?:[UNICODE_7D42]|[UNICODE_7D76])"],
                        "weight": 0.8
                    }
                }
            
            def detect_negative_thought_patterns(self, content: str) -> List[Dict[str, Any]]:
                detected_patterns = []
                for distortion_type, distortion_info in self.cognitive_distortions.items():
                    matches = []
                    for pattern in distortion_info["patterns"]:
                        matches.extend(re.findall(pattern, content, re.IGNORECASE))
                    
                    if matches:
                        confidence = min(1.0, len(matches) * distortion_info["weight"] * 0.2)
                        detected_patterns.append({
                            "type": distortion_type,
                            "name": distortion_info["name"],
                            "matches": matches,
                            "confidence": confidence,
                            "severity": "high" if confidence > 0.7 else "medium" if confidence > 0.4 else "low"
                        })
                
                return sorted(detected_patterns, key=lambda x: x["confidence"], reverse=True)
            
            def generate_story_break_dialog(self, detected_patterns: List[Dict[str, Any]], character_name: str = "[UNICODE_30E6]") -> str:
                if not detected_patterns:
                    return None
                
                primary_pattern = detected_patterns[0]
                return f"[UNICODE_3061]{character_name}[UNICODE_3002]\n\n[UNICODE_672C]\n\n[UNICODE_3053]\n\n[UNICODE_3042]"
        
        # [UNICODE_7D71]
        content_moderation = ContentModerationEngine()
        cbt_intervention = CBTInterventionEngine()
        
        # [UNICODE_30C6]1: [UNICODE_9AD8]
        high_risk_content = "[UNICODE_3082]"
        
        print(f"[UNICODE_30C6]: {high_risk_content}")
        
        # Step 1: [UNICODE_30B3]
        risk_score = content_moderation._calculate_custom_risk_score(high_risk_content)
        print(f"[UNICODE_2705] [UNICODE_30EA]: {risk_score:.3f}")
        
        # Step 2: [UNICODE_5426]
        negative_patterns = cbt_intervention.detect_negative_thought_patterns(high_risk_content)
        print(f"[UNICODE_2705] [UNICODE_691C]: {len(negative_patterns)}[UNICODE_500B]")
        for pattern in negative_patterns:
            print(f"   - {pattern['name']} ([UNICODE_4FE1]: {pattern['confidence']:.2f})")
        
        # Step 3: [UNICODE_30B9]
        story_break_dialog = cbt_intervention.generate_story_break_dialog(negative_patterns)
        print("[UNICODE_2705] [UNICODE_30B9]")
        print(f"   [UNICODE_30C0]: {story_break_dialog[:50]}...")
        
        # [UNICODE_30C6]2: [UNICODE_5B89]
        safe_content = "[UNICODE_4ECA]"
        
        print(f"\n[UNICODE_30C6]: {safe_content}")
        
        safe_risk_score = content_moderation._calculate_custom_risk_score(safe_content)
        safe_patterns = cbt_intervention.detect_negative_thought_patterns(safe_content)
        
        print(f"[UNICODE_2705] [UNICODE_5B89]: {safe_risk_score:.3f}")
        print(f"[UNICODE_2705] [UNICODE_691C]: {len(safe_patterns)}[UNICODE_500B]")
        
        # [UNICODE_7D71]
        def integrated_safety_assessment(content: str) -> Dict[str, Any]:
            # [UNICODE_30B3]
            risk_score = content_moderation._calculate_custom_risk_score(content)
            
            # CBT[UNICODE_4ECB]
            patterns = cbt_intervention.detect_negative_thought_patterns(content)
            
            # [UNICODE_7D71]
            needs_intervention = risk_score > 0.05 or len(patterns) > 0
            intervention_type = []
            
            if risk_score > 0.5:
                intervention_type.append("HUMAN_ESCALATION")
            if len(patterns) > 0:
                intervention_type.append("CBT_REFRAME")
                intervention_type.append("STORY_BREAK")
            
            return {
                "content_safe": risk_score < 0.02 and len(patterns) == 0,
                "risk_score": risk_score,
                "detected_patterns": patterns,
                "needs_intervention": needs_intervention,
                "intervention_types": intervention_type,
                "story_break_dialog": cbt_intervention.generate_story_break_dialog(patterns) if patterns else None
            }
        
        # [UNICODE_7D71]
        print("\n--- [UNICODE_7D71] ---")
        
        high_risk_assessment = integrated_safety_assessment(high_risk_content)
        safe_assessment = integrated_safety_assessment(safe_content)
        
        # [UNICODE_9AD8]
        assert high_risk_assessment["content_safe"] == False, "[UNICODE_9AD8]"
        assert high_risk_assessment["needs_intervention"] == True, "[UNICODE_9AD8]"
        assert len(high_risk_assessment["intervention_types"]) > 0, "[UNICODE_4ECB]"
        print("[UNICODE_2705] [UNICODE_9AD8]: [UNICODE_6B63]")
        
        # [UNICODE_5B89]
        assert safe_assessment["content_safe"] == True, "[UNICODE_5B89]"
        assert safe_assessment["needs_intervention"] == False, "[UNICODE_5B89]"
        print("[UNICODE_2705] [UNICODE_5B89]: [UNICODE_6B63]")
        
        print("\n[UNICODE_1F389] Task 9 [UNICODE_6CBB]!")
        return True
        
    except Exception as e:
        print(f"[UNICODE_274C] [UNICODE_7D71]: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """[UNICODE_30E1]"""
    print("Task 9: [UNICODE_6CBB] - [UNICODE_7D71]")
    print("=" * 60)
    
    success = test_therapeutic_safety_integration()
    
    if success:
        print("\n[UNICODE_1F389] Task 9 [UNICODE_5B8C]:")
        print("=" * 40)
        print("[UNICODE_2705] Task 9.1: [UNICODE_30B3]")
        print("   - OpenAI Moderation API[UNICODE_7D71]")
        print("   - [UNICODE_30AB]")
        print("   - 98% F1[UNICODE_30B9]")
        print("   - [UNICODE_5B89]")
        print()
        print("[UNICODE_2705] Task 9.2: CBT[UNICODE_30D9]")
        print("   - [UNICODE_5426]")
        print("   - [UNICODE_300C]")
        print("   - [UNICODE_8A8D]")
        print("   - CBT[UNICODE_4ECB]")
        print()
        print("[UNICODE_2705] [UNICODE_7D71]:")
        print("   - [UNICODE_30B3] + CBT[UNICODE_4ECB]")
        print("   - [UNICODE_30EA]")
        print("   - [UNICODE_6CBB]")
        print()
        print("[UNICODE_1F3C6] Task 9: [UNICODE_6CBB] - [UNICODE_5B8C]")
        return True
    else:
        print("[UNICODE_26A0]  [UNICODE_7D71]")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)